main:
  params: [args]
  steps:
    - init:
        assign:
        - project: ${sys.get_env("GOOGLE_CLOUD_PROJECT_ID")}
        - location: ${default(map.get(args, "location"), "us-central1")}
        - cloud_function: ${default(map.get(args, "cloud_function"), "gaarf")}
        - bq_dataset_location: ${if(default(map.get(args, "bq_dataset_location"), "us") == "", "us", default(map.get(args, "bq_dataset_location"), "us"))}
        - gcs_bucket: ${default(map.get(args,"gcs_bucket"), project)}
        - only_run_bq: ${default(map.get(args,"only_run_bq"), false)}
        - completion_topic: ${default(map.get(args, "completion_topic"), "gaarf_wf_completed")}
    - check_shortcut_arg:
        switch:
          - condition: ${only_run_bq}
            next: run_bq_workflow
        next: run_ads_workflow
    - run_ads_workflow:
        call: runAdsQueries
        args:
          project: ${project}
          location: ${location}
          function_name: ${cloud_function}
          gcs_bucket: ${gcs_bucket}
          queries_path: ${args.ads_queries_path}
          ads_config_path: ${args.ads_config_path}
          cid: ${args.cid}
          customer_ids_query: ${map.get(args, "customer_ids_query")}
          bq_dataset: ${args.dataset}
          bq_dataset_location: ${bq_dataset_location}
          macros: ${map.get(args, "ads_macro")}
          bq_writer_options: ${map.get(args, "bq_writer_options")}
    - run_bq_workflow:
        call: runBigQueryQueries
        args:
          project: ${project}
          location: ${location}
          function_name: ${cloud_function + "-bq"}
          gcs_bucket: ${gcs_bucket}
          queries_path: ${args.bq_queries_path}
          dataset_location: ${bq_dataset_location}
          macros: ${map.get(args, "bq_macro")}
          sqlParams: ${map.get(args, "bq_sql")}
    - create_completion_message:
        assign:
          - message: {"accounts": len(accounts)}
          - base64Msg: ${base64.encode(json.encode(message))}
    - publish_completion_message:
        call: googleapis.pubsub.v1.projects.topics.publish
        args:
          topic: ${"projects/" + project + "/topics/" + completion_topic}
          body:
            messages:
              - data: ${base64Msg}
        result: publishResult

runAdsQueries:
  params: [project, location, function_name, gcs_bucket, queries_path, ads_config_path, cid, customer_ids_query, bq_dataset, bq_dataset_location, macros, bq_writer_options]
  # NOTE: currently it's assumed that CF's project is the same as project for BQ datasets
  steps:
    # get CF 'gaarf' function's URL
    - get_function:
        call: http.get
        args:
          url: ${"https://cloudfunctions.googleapis.com/v2/projects/" + project + "/locations/" + location + "/functions/" + function_name}
          auth:
            type: OAuth2
        result: function
        # TODO: move to using CF adapter when it's ready (currently only v1 supported):
        #call: googleapis.cloudfunctions.v2.projects.locations.functions.get
        #args:
        #  name: ${"projects/" + project + "/locations/" + location + "/functions/" + function_name}
        #result: function
    # get CF 'gaarf-getcids' function's URL
    - get_function_cids:
        call: http.get
        args:
          url: ${"https://cloudfunctions.googleapis.com/v2/projects/" + project + "/locations/" + location + "/functions/" + function_name + "-getcids"}
          auth:
            type: OAuth2
        result: function_cids
    # get CF 'gaarf-bq-view' function's URL
    - get_function_view:
        call: http.get
        args:
          url: ${"https://cloudfunctions.googleapis.com/v2/projects/" + project + "/locations/" + location + "/functions/" + function_name + "-bq-view"}
          auth:
            type: OAuth2
        result: function_view
    - log_functions_metadata:
        call: sys.log
        args:
          json:
            gaarf: ${function.body.serviceConfig.uri}
            gaarf-getcids: ${function_cids.body.serviceConfig.uri}
            gaarf-bq-view: ${function_view.body.serviceConfig.uri}
    #call 'gaarf-getcids' CF to get a list of customer ids for further processing
    - call_gaarf_cids_cf:
        call: http.post
        args:
          url: ${function_cids.body.serviceConfig.uri}
          timeout: 1800 # maximum allowed timeout in Workflows is 1800 despite the fact CF gen2 support 3600
          query:
            ads_config_path: ${ads_config_path}
            customer_id: ${cid}
            customer_ids_query: ${default(customer_ids_query, "")}
          auth:
            type: OIDC
        result: accounts_response
    - set_accounts_from_cf_response:
        assign:
          - accounts: ${accounts_response.body}
    - log_cids:
        call: sys.log
        args:
          json:
            text: "accounts to process"
            count: ${len(accounts)}
            accounts: ${accounts}
          severity: "INFO"
    # fetch script from GCS
    - get_ads_scripts_from_gcs:
        call: googleapis.storage.v1.objects.list
        args:
          bucket: ${gcs_bucket}
          prefix: ${queries_path}
        result: scripts_raw

    - initialize_filtered_list:
        assign:
          - scripts: []

    - filter_sql_files:
        for:
          value: script_item
          in: ${scripts_raw.items}
          steps:
            - check_sql_extension:
                switch:
                  - condition: ${text.match_regex(script_item.name, "[.]sql$")}
                    assign:
                      - scripts: ${list.concat(scripts, script_item.name)}

    - log_ads_scripts:
        call: sys.log
        args:
          json:
            count: ${len(scripts)}
            scripts: ${scripts}
          severity: "INFO"
    # parallel loop over queries on GCS
    - runAdsQueries:
        parallel:
          shared: [scripts, accounts]
          for:
            value: script_item
            in: ${scripts}
            steps:
              - check_for_constant:
                  switch:
                    - condition: ${text.match_regex(script_item, "_constant")}
                      next: execute_constant_script
                  next: parallel_loop_over_accounts
              # execute constant query for a single (first) account
              - execute_constant_script:
                  call: executeAdsQuery
                  args:
                    cf_uri: ${function.body.serviceConfig.uri}
                    script_path: ${"gs://" + gcs_bucket + "/" + script_item}
                    account: ${accounts[0]}
                    macros: ${macros}
                    project: ${project}
                    bq_dataset: ${bq_dataset}
                    bq_dataset_location: ${bq_dataset_location}
                    ads_config_path: ${ads_config_path}
                    bq_writer_options: ${bq_writer_options}
                    is_constant: true
                  next: continue # continue loop over queries
              # parallel nested loop over accounts
              - parallel_loop_over_accounts:
                  parallel:
                    shared: [accounts]
                    for:
                      value: account
                      in: ${accounts}
                      steps:
                        - execute_script:
                            call: executeAdsQuery
                            args:
                              cf_uri: ${function.body.serviceConfig.uri}
                              script_path: ${"gs://" + gcs_bucket + "/" + script_item}
                              account: ${account}
                              macros: ${macros}
                              project: ${project}
                              bq_dataset: ${bq_dataset}
                              bq_dataset_location: ${bq_dataset_location}
                              ads_config_path: ${ads_config_path}
                              bq_writer_options: ${bq_writer_options}
              # create a view in BQ to combine all account tables into a single view
              - call_create_view_cf:
                  call: http.post
                  args:
                    url: ${function_view.body.serviceConfig.uri}
                    timeout: 1800
                    query:
                      project_id: ${project}
                      dataset: ${bq_dataset}
                      dataset_location: ${bq_dataset_location}
                      script_path: ${"gs://" + gcs_bucket + "/" + script_item}
                    body:
                      accounts: ${accounts}
                    auth:
                      type: OIDC
                  result: create_view_response
              # - log_script_completed:
              #     call: sys.log
              #     args:
              #       data:
              #         query: ${script_item.name}
              #         message: "Unified view created"
              #       severity: "INFO"

runBigQueryQueries:
  params: [project, location, function_name, gcs_bucket, queries_path, macros, sqlParams, dataset_location]
  steps:
    - get_bq_scripts_from_gcs:
        call: googleapis.storage.v1.objects.list
        args:
          bucket: ${gcs_bucket}
          prefix: ${queries_path}
        result: bq_scripts_raw

    # check if there are any bq scripts on GCS
    - check_scripts:
        switch:
          - condition: ${map.get(bq_scripts_raw, "items") != null and len(map.get(bq_scripts_raw, "items")) > 0}
            next: initialize_filtered_list
        next: end

    - initialize_filtered_list:
        assign:
          - bq_scripts: []

    - filter_sql_files:
        for:
          value: bq_script_item
          in: ${bq_scripts_raw.items}
          steps:
            - check_sql_extension:
                switch:
                  - condition: ${text.match_regex(bq_script_item.name, "[.]sql$")}
                    assign:
                      - bq_scripts: ${list.concat(bq_scripts, bq_script_item.name)}

    - log_bq_scripts:
        call: sys.log
        args:
          data: ${bq_scripts}
          severity: "INFO"
    # get clound function's uri
    - get_function_bq:
        call: http.get
        args:
          url: ${"https://cloudfunctions.googleapis.com/v2/projects/" + project + "/locations/" + location + "/functions/" + function_name}
          auth:
            type: OAuth2
        result: function_bq
        # TODO: move to using CF adapter when it's ready (currently only v1 supported):
        #call: googleapis.cloudfunctions.v2.projects.locations.functions.get
        #args:
        #  name: ${"projects/" + project + "/locations/" + location + "/functions/" + function_name}
        #result: function_bq
    - runBqQueries:
        for:
          value: bq_script_item
          in: ${bq_scripts}
          steps:
            - call_gaarf_bq_cf:
                try:
                  call: http.post
                  args:
                    url: ${function_bq.body.serviceConfig.uri}
                    timeout: 1800
                    query:
                      script_path: ${"gs://" + gcs_bucket + "/" + bq_script_item}
                      project_id: ${project}
                      dataset_location: ${dataset_location}
                    body:
                      macro: ${macros}
                      sql: ${sqlParams}
                    auth:
                      type: OIDC
                  result: script_results
                retry:
                  predicate: ${custom_retry_predicate}
                  max_retries: 3
                  backoff:
                    initial_delay: 2
                    max_delay: 60
                    multiplier: 2
            - log_script_bq_result:
                call: sys.log
                args:
                  data: ${script_results.body}
                  severity: "INFO"

executeAdsQuery:
  params: [cf_uri, script_path, account, macros, project, bq_dataset, bq_dataset_location, ads_config_path, bq_writer_options, is_constant: false]
  steps:
    - init_vars:
        assign:
          - started: ${sys.now()}
    - call_gaarf_cf:
        try:
          call: http.post
          args:
            url: ${cf_uri}
            timeout: 1800 # maximum allowed timeout in Workflows is 1800 (30min) despite the fact CF gen2 support 3600 (60min)
            query:
              script_path: ${script_path}
              ads_config_path: ${ads_config_path}
              bq_project_id: ${project}
              bq_dataset: ${bq_dataset}
              bq_dataset_location: ${bq_dataset_location}
              customer_id: ${account}
              single_customer: true # it's important to prevent fetching child accounts for the supplied cid
            body:
              macro: ${macros}
              bq_writer_options: ${bq_writer_options}
            auth:
              type: OIDC
          result: script_results
        retry:
          predicate: ${custom_retry_predicate}
          max_retries: 3
          backoff:
            initial_delay: 2
            max_delay: 60
            multiplier: 2
    - log_script_result:
        call: sys.log
        args:
          data:
            is_constant: ${is_constant}
            query: ${script_path}
            account: ${account}
            rowCount: ${map.get(script_results.body, "" + account)}
            started: ${time.format(started)}
            elapsed: ${sys.now() - started}
          severity: "INFO"

custom_retry_predicate:
  params: [e]
  steps:
    - log_call_gaarf_cf_failure:
        call: sys.log
        args:
          data: ${e}
          severity: "WARNING"
    - what_to_repeat:
        switch:
          # We'll repeat if it's a ConnectionError, TimeoutError or http statuses:
          #   429 - Too Many Requests
          #   502 - Bad Gateway 
          #   503 - Service Unavailable
          #   504 - Gateway Timeout 
          # NOTE: sometime errors happen inside Workflow and there's no any code
          # (i.e. "code" can be null, so DO NOT use operand ==,<,>,>=,<= without wrapping with `default`
          - condition: ${"ConnectionFailedError" in default(map.get(e, "tags"), []) or "ConnectionError" in default(map.get(e, "tags"), []) or "TimeoutError" in default(map.get(e, "tags"), []) or default(map.get(e, "code"),0) == 429 or default(map.get(e, "code"),0) == 502 or default(map.get(e, "code"),0) == 503 or default(map.get(e, "code"),0) == 504}
            return: true
    - otherwise:
        return: false
